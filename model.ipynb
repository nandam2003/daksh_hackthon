{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jahnav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title              author  \\\n",
      "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
      "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
      "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
      "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
      "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
      "\n",
      "                                                text  label  \n",
      "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
      "1  Ever get the feeling your life circles the rou...      0  \n",
      "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
      "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
      "4  Print \\nAn Iranian woman has been sentenced to...      1  \n",
      "20800\n",
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "label     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "print(df.head())\n",
    "print(len(df))\n",
    "\n",
    "df.isnull().sum()\n",
    "df = df.fillna(' ')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jahnav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jahnav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jahnav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1  Ever get the feeling your life circles the rou...   \n",
      "2  Why the Truth Might Get You Fired October 29, ...   \n",
      "3  Videos 15 Civilians Killed In Single US Airstr...   \n",
      "4  Print \\nAn Iranian woman has been sentenced to...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  house dem aide : ’ even see comey ’ letter jas...  \n",
      "1  ever get feeling life circle roundabout rather...  \n",
      "2  truth might get fired october 29 , 2016 tensio...  \n",
      "3  video 15 civilian killed single u airstrike id...  \n",
      "4  print iranian woman sentenced six year prison ...  \n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocessing(msg):\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(msg)\n",
    "    # Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # Removing stop words\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocessing)\n",
    "\n",
    "print(df[['text', 'processed_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 95.0\n",
      "Naive Bayes Accuracy: 88.07692307692308\n",
      "Decision Tree Accuracy: 89.15865384615384\n"
     ]
    }
   ],
   "source": [
    "X = df['processed_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform text data to TF-IDF features\n",
    "tf_idf_matrix_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tf_idf_matrix_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(tf_idf_matrix_train, y_train)\n",
    "accuracy_logreg = logreg.score(tf_idf_matrix_test, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg * 100)\n",
    "\n",
    "# Naive Bayes\n",
    "NB = MultinomialNB()\n",
    "NB.fit(tf_idf_matrix_train, y_train)\n",
    "accuracy_NB = NB.score(tf_idf_matrix_test, y_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_NB * 100)\n",
    "\n",
    "# Decision Tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(tf_idf_matrix_train, y_train)\n",
    "accuracy_decision_tree = clf.score(tf_idf_matrix_test, y_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_decision_tree * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_regression_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "svm_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC(probability=True))\n",
    "])\n",
    "\n",
    "rf_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "# bert_model_name = \"bert-base-uncased\"\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "# bert_model = BertForSequenceClassification.from_pretrained(bert_model_name)\n",
    "\n",
    "# bert_classifier = pipeline('sentiment-analysis', model=bert_model, tokenizer=bert_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# max_words = 1000  \n",
    "# max_sequence_length = 50\n",
    "# lstm_model = Sequential([\n",
    "#     # Embedding(max_words, 64, input_length=max_sequence_length),\n",
    "#     LSTM(64),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# lstm_classifier = KerasClassifier(build_fn=lstm_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('lr', logistic_regression_model),\n",
    "    ('svm', svm_model),\n",
    "    ('rf', rf_model)\n",
    "    # ('bert', bert_classifier)\n",
    "    # ('lstm', lstm_classifier)\n",
    "], voting='soft') \n",
    "\n",
    "\n",
    "\n",
    "X = df['processed_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.22596153846153\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
